from smolagents import CodeAgent, DuckDuckGoSearchTool, ManagedAgent, LiteLLMModel
import gradio as gr
from gradio import ChatMessage
from utils import stream_from_transformers_agent
import time

model = LiteLLMModel(
    model_id="ollama/qwen2.5-coder-extra:latest",
    api_base="http://ollama.webtw.xyz:11434",
    api_key="ollama",
)

class CustomAgent(CodeAgent):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.thought_callback = None
    
    def run(self, prompt: str) -> str:
        try:
            # è¨˜éŒ„é–‹å§‹æ™‚é–“
            start_time = time.time()
            
            # åŸ·è¡Œæœå°‹ä¸¦ç²å–å›æ‡‰
            response = super().run(prompt)
            
            # ç¢ºä¿å›æ‡‰æ˜¯å­—ä¸²é¡å‹
            if not isinstance(response, str):
                response = str(response)
            
            # è¨ˆç®—è™•ç†æ™‚é–“
            process_time = time.time() - start_time
            response = f"{response}\n\nè™•ç†æ™‚é–“: {process_time:.2f} ç§’"
            
            return response
            
        except Exception as e:
            return f"ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

web_agent = CustomAgent(
    tools=[DuckDuckGoSearchTool()], 
    model=model
)

managed_web_agent = ManagedAgent(
    agent=web_agent,
    name="web_search",
    description="Runs web searches for you. Give it your query as an argument."
)

manager_agent = CustomAgent(
    tools=[],
    model=model,
    managed_agents=[managed_web_agent]
)

def create_interface():
    with gr.Blocks(theme=gr.themes.Soft(primary_hue="blue")) as interface:
        gr.Markdown("""
        # ğŸ¤– AI æ™ºèƒ½åŠ©æ‰‹
        é€™æ˜¯ä¸€å€‹å¯ä»¥å¹«åŠ©æ‚¨æœå°‹ç¶²è·¯è³‡è¨Šçš„ AI åŠ©æ‰‹ã€‚æ‚¨å¯ä»¥ï¼š
        - è©¢å•ä»»ä½•å•é¡Œ
        - ç²å–å³æ™‚ç¶²è·¯è³‡è¨Š
        - æŸ¥çœ‹ AI çš„æ€è€ƒéç¨‹
        """)
        
        chatbot = gr.Chatbot(
            height=500,
            show_label=False,
            container=True,
            show_copy_button=True,
            bubble_full_width=False,
        )
        
        with gr.Row():
            input_text = gr.Textbox(
                placeholder="è«‹è¼¸å…¥æ‚¨çš„å•é¡Œ...",
                lines=2,
                label="è¼¸å…¥",
                show_label=False,
                scale=8
            )
            submit_btn = gr.Button("é€å‡º", variant="primary", scale=1)
            clear_btn = gr.Button("æ¸…é™¤", scale=1)

        gr.Examples(
            examples=[
                "è«‹å¹«æˆ‘æœå°‹æœ€æ–°çš„ AI æŠ€è¡“ç™¼å±•è¶¨å‹¢",
                "ä»€éº¼æ˜¯å¤§å‹èªè¨€æ¨¡å‹ï¼Ÿ",
                "è«‹è§£é‡‹ä¸€ä¸‹ Docker çš„åŸºæœ¬æ¦‚å¿µ",
            ],
            inputs=input_text,
        )

        state = gr.State([])

        def respond(message, chat_history, state):
            try:
                # æ›´æ–°å°è©±æ­·å²
                chat_history = chat_history or []
                
                # ä½¿ç”¨ agent mode è™•ç†å›æ‡‰
                response = manager_agent.run(message)
                
                # æ›´æ–°å°è©±æ­·å²
                chat_history.append((message, response))
                state.append((message, response))
                
                return "", chat_history, state
                
            except Exception as e:
                error_msg = f"è™•ç†è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
                chat_history.append((message, error_msg))
                state.append((message, error_msg))
                return "", chat_history, state

        def clear_history():
            return [], [], []

        submit_btn.click(
            respond,
            inputs=[input_text, chatbot, state],
            outputs=[input_text, chatbot, state],
        )

        input_text.submit(
            respond,
            inputs=[input_text, chatbot, state],
            outputs=[input_text, chatbot, state],
        )

        clear_btn.click(
            clear_history,
            outputs=[chatbot, state, input_text],
        )

    return interface

def interact_with_agent(prompt, messages):
    messages.append(ChatMessage(role="user", content=prompt))
    yield messages
    for msg in stream_from_transformers_agent(manager_agent, prompt):
        messages.append(msg)
        yield messages
    yield messages


with gr.Blocks() as demo:
    stored_message = gr.State([])
    chatbot = gr.Chatbot(label="Agent",
                         type="messages",
                         avatar_images=(None, "https://em-content.zobj.net/source/twitter/53/robot-face_1f916.png"))
    text_input = gr.Textbox(lines=1, label="Chat Message")
    text_input.submit(lambda s: (s, ""), [text_input], [stored_message, text_input]).then(interact_with_agent, [stored_message, chatbot], [chatbot])

if __name__ == "__main__":
    # interface = create_interface1()
    # interface.queue()
    # interface.launch(
    #     server_name="0.0.0.0",
    #     server_port=7860,
    #     share=True,
    #     debug=True
    # )
    demo.launch()